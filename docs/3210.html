<html>
<head>
<title>Deploying Natural JS Inference Models to AWS Lambda</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将自然JS推理模型部署到AWS Lambda</h1>
<blockquote>原文：<a href="https://javascript.plainenglish.io/deploying-natural-js-inference-model-to-aws-lambda-ff2f9719b5d0?source=collection_archive---------5-----------------------#2020-09-09">https://javascript.plainenglish.io/deploying-natural-js-inference-model-to-aws-lambda-ff2f9719b5d0?source=collection_archive---------5-----------------------#2020-09-09</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/990fc77d48721dd67b4b85b9cdc7fc7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_6f7PwuV8Mg4i6QecJ95Qg.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">A comprehensive guide on embedding pre-trained inference models inside serverless APIs</figcaption></figure><p id="7257" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">本文是一个全面的指南，解释了如何使用AWS Lambda &amp; API网关将使用Natural JS训练的推理模型部署到受密钥保护的API。在本文结束时，您应该能够:</p><ul class=""><li id="7b91" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated"><em class="lg">理解什么是推理模型。</em></li><li id="0331" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><em class="lg">对ML管道及其与推理模型的关系有基本的了解。</em></li><li id="6a68" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><em class="lg">在无服务器API中部署推理模型的优势。</em></li><li id="cdcb" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><em class="lg">用嵌入式推理模型构建无服务器API</em></li><li id="abbc" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><em class="lg">部署受API网关、使用计划、速率限制和API密钥保护的Lambda功能。</em></li><li id="c825" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><em class="lg">实现与Lambda功能开发相关的常见任务的自动化。</em></li></ul><h2 id="cdee" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">第1部分:好奇如何构建纯JS模型？</h2><p id="48e8" class="pw-post-body-paragraph jz ka in kb b kc mf ke kf kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw ig bi translated">如果您想知道本文中使用的模型是如何训练的，我建议您在继续阅读本页之前先阅读下面的文章！</p><div class="mk ml gp gr mm mn"><a href="https://medium.com/javascript-in-plain-english/ml-for-js-devs-in-10-minutes-46794782762e" rel="noopener follow" target="_blank"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd io gy z fp ms fr fs mt fu fw im bi translated">JavaScript开发者的机器学习将在10分钟内完成</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">本文旨在向JavaScript开发人员介绍并教授不到10分钟的机器学习:</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">medium.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb jt mn"/></div></div></a></div><h2 id="1603" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">机器学习管道&amp;推理模型</h2><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/9a2f1f54dc6c2b00258faa08e3cd8dba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vyBgzT1zJ3kzfb46fBvGeQ.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">A typical machine learning pipeline that produces inferences model(s).</figcaption></figure><p id="ce4d" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">推理模型是机器学习管道的最终产品。典型的ML管道由几个旨在产生推理模型的步骤组成。最后，这些管道可能因具体情况而异，并可能在流程结束时产生一个或多个模型。</p><p id="4ca0" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">我个人喜欢在我的项目中使用的ML管道由以下步骤组成:</p><ul class=""><li id="843a" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated"><strong class="kb io">数据收集</strong> —机器学习工程师和数据科学家从不同来源收集和整理数据，以便将其用于模型培训的步骤。</li><li id="5f16" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><strong class="kb io">数据预处理</strong> —对采集的数据进行清理和转换的步骤。这一步是完全可选的，但通常可以提高推理模型产生的结果的质量和准确性。</li><li id="2c15" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><strong class="kb io">算法选择</strong> —机器学习工程师选择一个或多个在解决问题陈述中表现良好的算法的步骤。</li><li id="e7ef" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><strong class="kb io">验证</strong> —“表现良好”通过验证技术确定，例如K-fold &amp; 80/20技术。我将写另一篇文章，展示这一具体步骤，以提高我们推理模型的当前准确性(71%)。</li><li id="c54e" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><strong class="kb io">最终培训</strong> —培训将嵌入到生产API中的模型的步骤。</li></ul><p id="5521" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在这些管道的末端，推理模型被用在商业应用中，用于预测来自给定输入的结果。在我们的解决方案的上下文中，我们的推理模型被构建为在以下标签之间对一段文本进行分类:</p><ul class=""><li id="b403" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">仇恨言论</li><li id="7274" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">攻击性言论</li><li id="887c" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">也不</li></ul><h2 id="e040" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">在应用编程接口中部署推理模型</h2><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ng"><img src="../Images/e8197cbedbea6f8399e17b9ad074e2a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r2aAaKXwAJjx-uy-SSWh9Q.png"/></div></div></figure><p id="6e78" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在API中嵌入机器学习模型是服务于其功能的最常见方式。使用API公开它比将其嵌入到客户端应用程序中更理想，因为:</p><ul class=""><li id="e8fc" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">模型权重通常很大，不适合通过网络传输，这会降低前端应用程序的加载速度</li><li id="4ac9" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">它允许你在客户端保护你的模型免受<a class="ae nh" href="https://towardsdatascience.com/beware-of-weight-poisoning-in-transfer-learning-4c09b63f8353" rel="noopener" target="_blank">体重中毒攻击</a></li><li id="e06a" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">它允许你保护你的模型不被抄袭。</li><li id="6aa9" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">它允许您对机器学习模型应用安全措施(速率限制、使用配额和API密钥)</li><li id="a588" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">它允许你为不同的消费者提供服务</li></ul><h2 id="7d67" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">为什么选择AWS Lambda？</h2><p id="7518" class="pw-post-body-paragraph jz ka in kb b kc mf ke kf kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw ig bi translated">个人和组织会希望将机器学习模型部署到AWS Lambda，因为它允许他们利用以下优势:</p><ul class=""><li id="1a6a" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">无需前期成本的快速原型制作</li><li id="7884" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">如果实验失败，易于退役</li><li id="e216" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">一旦原型成功，易于扩展</li><li id="56cf" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">不需要您支付闲置的计算时间</li><li id="873a" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">不需要IT和安全人员的大量关注和管理</li><li id="c6e7" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">借助AWS API网关，实现API密钥保护机制更容易</li><li id="6f52" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">本地<a class="ae nh" href="https://aws.amazon.com/blogs/compute/implementing-canary-deployments-of-aws-lambda-functions-with-alias-traffic-shifting/" rel="noopener ugc nofollow" target="_blank">金丝雀部署</a>，借助SAM模板进行模型性能比较</li></ul><p id="c92d" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">你可以从这个<a class="ae nh" href="https://itnext.io/serverless-ninja-part-01-serverless-efficiency-64cf77915838" rel="noopener ugc nofollow" target="_blank">链接</a>找到更多关于使用无服务器架构优势的信息。</p><h2 id="ccca" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">注入人工智能的API解决方案</h2><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ni"><img src="../Images/5a3d5c55f6f2471ac467948eeff00df6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Dih3N_nkPHnS38qpaxM1g.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">A high-level overview of this project’s architecture</figcaption></figure><p id="7fc6" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">既然我们已经讨论了为什么ML模型在API中更好地服务，我们可以继续解释ML驱动的API设计的高级概述。</p><p id="ac34" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">在上图中:</p><ul class=""><li id="df31" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">开发人员构建注入人工智能的API包，并将其上传到S3桶</li><li id="65fb" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">Lambda服务从S3桶中检索部署工件和云形成模板</li><li id="a307" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">该模型嵌入在基于Lambda的API中</li><li id="156f" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">基于Lambda的API受到AWS API网关的保护</li><li id="73eb" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">API网关受API密钥保护</li><li id="b8c2" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">消费者调用API网关上的端点</li></ul><h2 id="afe3" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">克隆源代码</h2><p id="4c7e" class="pw-post-body-paragraph jz ka in kb b kc mf ke kf kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw ig bi translated">为了运行和测试推理端点，请从Github中我的书的代码库的这个<a class="ae nh" href="https://github.com/allanchua101/serverless-ninja/tree/master/006-ai-apis/002-apis/natural-js-simple" rel="noopener ugc nofollow" target="_blank">文件夹</a>中克隆您机器上的整个实现。</p><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/3af4c4dd39aa34d63f75fa694840004b.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*JmJeSvOFCMUx3KbHJFH1UA.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">The scaffold of our AI-powered serverless API</figcaption></figure><p id="b51b" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">克隆过程完成后，您将在机器上看到以下文件夹结构(Scaffold)。</p><h2 id="0a11" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">安装API依赖项</h2><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nk"><img src="../Images/0eabfb8e684508575e47548fd122b3b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q17W0bebmPkJZnRGtelRPQ.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">CLI output of dependency installers</figcaption></figure><p id="0270" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">要安装我们的API的依赖项(自然JS的节点模块)，您可以在您的终端中运行名为<strong class="kb io">001 _ install _ dependencies . sh</strong>的脚本。</p><p id="8c97" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">这个脚本的作用是查找项目根目录下的所有文件夹，如果开发机器上没有节点模块，就安装节点模块。</p><p id="39e3" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">我以这种方式自动化了依赖项安装，因为现实生活中的无服务器项目将包含不止一个基于Lambda的API，如果手动安装，跨所有这些端点安装节点模块会花费您大量的时间。</p><h2 id="8c0f" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">检查API代码</h2><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/3dfabba6404012f8289f153ca3943f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*TKOJvqEwroiqqFlPRzj8-Q.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">An ML-powered API designed for classifying hate speech. The code is also viewable in a <a class="ae nh" href="https://gist.github.com/allanchua101/64c1ab5134e183bd0564497a1b686f36" rel="noopener ugc nofollow" target="_blank">gist</a>.</figcaption></figure><p id="ec98" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">为了让代码更具可读性，我删除了一些你可能会在<a class="ae nh" href="https://github.com/allanchua101/serverless-ninja/tree/master/006-ai-apis/002-apis/natural-js-simple" rel="noopener ugc nofollow" target="_blank"> Github </a>的源代码中找到的注释。</p><p id="6be2" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">下面是这段代码的逻辑分解:</p><ul class=""><li id="0e0b" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">该模块首先从实用程序文件导入到<a class="ae nh" href="https://github.com/allanchua101/serverless-ninja/blob/master/006-ai-apis/002-apis/natural-js-simple/infer/helpers/response-builders.js" rel="noopener ugc nofollow" target="_blank">build response</a>&amp;<a class="ae nh" href="https://github.com/allanchua101/serverless-ninja/blob/master/006-ai-apis/002-apis/natural-js-simple/infer/helpers/model-loader.js" rel="noopener ugc nofollow" target="_blank">loadFrozenModel</a>函数。</li><li id="b876" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">我们为模型的权重路径定义了一个常量变量。</li><li id="e356" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">我们定义了一个名为model的变量，并给它赋值null。其目的是<em class="lg">防止<strong class="kb io">热启动</strong>时不必要的从磁盘重新加载</em>推理模型的权重。</li><li id="064c" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">当使用<strong class="kb io">选项</strong>动词调用函数时，我们用HTTP 200进行响应。</li><li id="9a99" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">当没有提供要分类的正文或文本时，我们用HTTP 422(不可处理的实体)进行响应。</li><li id="6204" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">如果请求是<strong class="kb io">冷启动</strong>，我们将加载推理模型。</li><li id="a93b" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">如果所有参数和条件都有效，我们使用推理模型运行分类。</li><li id="8338" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">然后，我们用带有文本分类标签的HTTP 200进行响应。</li></ul><h2 id="3c2e" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">使用SAM定义API网关</h2><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/6690c1f9de457352c9e512b3a49199cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*WtHyjVAjLeiWUIsjwZDq1g.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Nothing special about our API gateway’s SAM template here</figcaption></figure><p id="e64d" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">从消费者的角度来看，为了将lambda函数聚合在一个单一的联系点下，我们将使用一个<a class="ae nh" href="https://www.pogsdotnet.com/2018/08/api-gateway-in-nutshell.html" rel="noopener ugc nofollow" target="_blank"> API网关</a>。上面的模板定义了我们的API网关。</p><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/ed03e1c14fcd4d97c6261ef79f16e0b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*bPynRPwgDkBL3ssIi7ZYmQ.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Defining an API key, API usage plan, and associating both to API Gateway</figcaption></figure><p id="ffcc" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">然后，我们定义一个API密钥，消费方需要这个密钥来验证传入的HTTP请求。我们还定义了一个实施以下内容的使用计划:</p><ul class=""><li id="ec11" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">将传入请求限制在每月10，000次的配额</li><li id="0123" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">每秒1，000次呼叫的节流设置为稳态速率限制</li><li id="67ea" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated"><a class="ae nh" href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html" rel="noopener ugc nofollow" target="_blank">阻止API网关过载的节流脉冲限制</a>(设置为1000)</li></ul><h2 id="e12f" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">λ函数定义</h2><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div class="gh gi no"><img src="../Images/bad1e97d1ae017482c71548ffc2779fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*0KDsEY3SP8E-5vgxVLhiJQ.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">SAM template definition for the API</figcaption></figure><ul class=""><li id="bec2" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">我们正在定义一个动态函数名，它附加了环境代码、应用程序名和我们的lambda函数名(<strong class="kb io"> infer-hate-speech </strong>)。</li><li id="fed0" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">指定端点的代码URI(推断目录)</li><li id="c929" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">指定Lambda函数执行入口点(app.execute)</li><li id="d84b" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">以秒(30)为单位指定最大请求超时</li><li id="71d5" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">指定函数运行时(nodejs10.x)</li><li id="b085" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">指定内存大小(256mb)</li><li id="3a5f" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">指定环境变量，以便在后面的教程中进行调试</li><li id="b11a" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">将API网关的<strong class="kb io"> POST &amp; OPTIONS </strong>动词事件作为触发器</li><li id="230b" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">将其标记为<a class="ae nh" href="https://docs.aws.amazon.com/ARG/latest/userguide/welcome.html" rel="noopener ugc nofollow" target="_blank">资源组管理</a></li></ul><h2 id="d6de" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">代码发布</h2><figure class="nc nd ne nf gt jo"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="2301" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">我创建了一个很棒的bash脚本，让你们可以运行引导部署，可以在这里找到<a class="ae nh" href="https://github.com/allanchua101/serverless-ninja/blob/master/006-ai-apis/002-apis/natural-js-simple/002_release_apis.sh" rel="noopener ugc nofollow" target="_blank"/>。如果您有兴趣使用自己的bash脚本集来发布它，您可以在项目根目录上运行以下命令:</p><figure class="nc nd ne nf gt jo"><div class="bz fp l di"><div class="nr nq l"/></div></figure><p id="cd64" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">如果您已经向我们的awesome guided CLI提供了有效值，您应该会得到类似于下图的云形成堆栈:</p><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ns"><img src="../Images/aec8a805f7429168c8b19d5861985fa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CYRvWniQh-7vz3ccBehiUQ.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Cloud Formation stack sample</figcaption></figure><h2 id="bb8a" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">测试我们的API</h2><p id="2943" class="pw-post-body-paragraph jz ka in kb b kc mf ke kf kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw ig bi translated">为了测试我们的模型与API Gateway &amp; Lambda函数的集成:</p><ul class=""><li id="1907" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">在AWS控制台中打开API网关。</li><li id="ca84" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">选择名为<strong class="kb io">dev-ninja-hate-inference-API的API网关。</strong></li><li id="def0" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">提供所需的文本，以下列有效负载格式进行分类</li></ul><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/07afd8728d0796187ac2439dfcbe50c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*XWGRp67Re2MLZLlrGSkhxg.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Sample text classification payload</figcaption></figure><ul class=""><li id="0f69" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">单击test按钮，您应该会看到以下结果</li></ul><figure class="nc nd ne nf gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi nu"><img src="../Images/f51831ed85f5ee8b40f77bf0527f5402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C-guY5l4J8R2CqeqTk7HSw.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Sample result for the provided input</figcaption></figure><h2 id="8427" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">使退役</h2><p id="c6a8" class="pw-post-body-paragraph jz ka in kb b kc mf ke kf kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw ig bi translated">在您完成摆弄和测试解决方案之后。如果您想保持AWS环境的整洁，我强烈建议停用云形成堆栈。</p><p id="c1c9" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">如果您希望在您的生态系统上保留CloudFormation堆栈以供将来测试或演示之用，这也是很好的。保持堆栈不需要花钱，除非你开始达到每月100万个请求。</p><p id="86b0" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">如果您决定退役API栈示例，您可以利用我从这个<a class="ae nh" href="https://github.com/allanchua101/serverless-ninja/blob/master/006-ai-apis/002-apis/natural-js-simple/003_decommission_apis.sh" rel="noopener ugc nofollow" target="_blank">链接</a>构建的退役bash脚本。</p><p id="4a3b" class="pw-post-body-paragraph jz ka in kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ig bi translated">让云形成堆栈在我们的AWS生态系统中运行的能力展示了无服务器的成本效率，这是基于Docker的推理模型无法轻松实现的，因为它需要您支付K8s控制平面(每月75美元)和工作节点(取决于是否使用AWS Fargate或EC2机器)。</p><h2 id="8303" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">结论</h2><p id="7333" class="pw-post-body-paragraph jz ka in kb b kc mf ke kf kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw ig bi translated">在本文中，我们了解到:</p><ul class=""><li id="8def" class="kx ky in kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">推理模型是训练机器学习模型的最终产品</li><li id="18cd" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">推理模型可以嵌入客户端应用程序或API中</li><li id="ef66" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">我们已经了解了将推理模型封装在无服务器API中的好处</li><li id="8386" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">我们已经看到了由API网关和API密钥保护的人工智能API的实际实现</li><li id="8784" class="kx ky in kb b kc lh kg li kk lj ko lk ks ll kw lc ld le lf bi translated">我们比较了在无服务器和基于Docker的API中嵌入ML模型的实验成本</li></ul><h2 id="edaf" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">下一步是什么？</h2><p id="681e" class="pw-post-body-paragraph jz ka in kb b kc mf ke kf kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw ig bi translated">在前一篇文章中，我们已经在开发机器中训练了我们的推理模型。然而，我们可以通过在lambda函数中运行我们的模型训练来将这带到下一个级别，lambda函数可以通过在S3桶上放置新的数据集来触发。</p><h2 id="b2bc" class="lm ln in bd lo lp lq dn lr ls lt dp lu kk lv lw lx ko ly lz ma ks mb mc md me bi translated">简单英语的JavaScript</h2><p id="3428" class="pw-post-body-paragraph jz ka in kb b kc mf ke kf kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw ig bi translated">喜欢这篇文章吗？如果是这样，通过<a class="ae nh" href="https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw" rel="noopener ugc nofollow" target="_blank"> <strong class="kb io">订阅解码获得更多类似内容，我们的YouTube频道</strong> </a> <strong class="kb io">！</strong></p></div></div>    
</body>
</html>