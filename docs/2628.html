<html>
<head>
<title>Using Node.js in Production (Part II)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在生产中使用Node.js(第二部分)</h1>
<blockquote>原文：<a href="https://javascript.plainenglish.io/using-node-js-in-production-ii-c3906990e61e?source=collection_archive---------7-----------------------#2020-07-10">https://javascript.plainenglish.io/using-node-js-in-production-ii-c3906990e61e?source=collection_archive---------7-----------------------#2020-07-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f316" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何将Node.js应用程序部署到生产环境中，并拥有从开发到部署的健壮管道</h2></div><p id="534c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是关于如何将Node.js应用程序部署到生产环境中的系列文章的第2部分，以便从开发到部署有一个健壮的管道。在这一部分，我们将把NGINX设置为反向代理，并做一些基本的负载平衡。</p><p id="2208" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您还没有阅读第1部分，我强烈建议您这样做，以确保您对本文有一个相关的背景。你可以在这里阅读:</p><div class="lb lc gp gr ld le"><a href="https://medium.com/@ryan.dsilva/using-node-js-in-production-i-e747e4091934" rel="noopener follow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">在生产中使用node . js—I</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">这将是一个关于如何将Node.js应用程序部署到生产环境中并拥有一个健壮的…</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">medium.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls lt le"/></div></div></a></div><p id="1ab0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们清除我在这篇文章的描述中使用的术语。什么是反向代理？首先，什么是代理？</p><p id="f140" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lu">代理服务器是一种中介服务器，它将来自多个客户端的内容请求通过互联网转发到不同的服务器。</em> <strong class="kh ir"> <em class="lu">反向代理服务器</em> </strong> <em class="lu">是一种代理服务器，通常位于私有网络中的防火墙之后，并将客户端请求定向到适当的后端服务器。反向代理提供了额外的抽象和控制级别，以确保客户端和服务器之间的网络流量顺畅流动。</em></p><p id="176f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简单地说，它位于客户机和主服务器之间，将客户机的请求转发给服务器，并将服务器的响应返回给客户机，还有一些额外的好处。</p><h2 id="d073" class="lv lw iq bd lx ly lz dn ma mb mc dp md ko me mf mg ks mh mi mj kw mk ml mm mn bi translated">什么是负载平衡？</h2><p id="24cd" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated"><em class="lu">负载平衡指的是将一组任务分配给一组资源的过程，目的是使它们的整体处理更加高效。</em></p><p id="cba9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好吧，那我们为什么需要这些东西？</p><p id="bddd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">嗯，主要有两个原因:</p><ol class=""><li id="d12c" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated">每当我们运行任何服务器端应用程序时，端口80(默认HTTP端口)是禁止使用的，除非您是root用户，而在部署应用程序时，您不应该是root用户。因此，您必须在另一个可用端口上运行您的应用程序— 3000、5000、8080等。所以每当你的应用程序需要被访问时，用户必须使用<code class="fe nc nd ne nf b">http://yourwebsite.com:PORT</code>，这不是特别好。为了避免这种情况，我们使用一个运行在默认端口80上的web服务器，它位于Node.js应用程序的前面。web服务器只是在内部将端口80上的传入请求代理给运行在我们定义的任何端口上的Node.js应用程序，并以同样的方式返回响应。这允许我们通过访问<code class="fe nc nd ne nf b">http://yourwebsite.com</code>在默认端口80上发送和接收数据</li><li id="293b" class="mt mu iq kh b ki ng kl nh ko ni ks nj kw nk la my mz na nb bi translated">Node.js应用程序是单线程的，因此如果您的服务器上有多个线程(大多数情况下都是这样)，您就没有有效地利用服务器资源。为了克服这个问题，我们使用像PM2这样的进程管理器运行Node.js的多个实例(阅读第1部分以了解更多信息),来运行与您可用的线程/内核数量相等的Node.js进程。然后，web服务器接收传入的请求，并将其分发到当前空闲的Node.js进程，这有助于为更多的请求提供服务，而不仅仅是运行一个实例。</li></ol><p id="dd9b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，为了完成这两件事，我们将使用<a class="ae nl" href="https://www.nginx.com/" rel="noopener ugc nofollow" target="_blank"> NGINX </a>，一个经过测试的网络服务器，可以充当反向代理和负载平衡器等许多其他功能。</p><figure class="nn no np nq gt nr gh gi paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="gh gi nm"><img src="../Images/3ecf1e9119a819fbd7df8d22723379a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n9iJF6XZt31HBuuabuUg1A.png"/></div></div><figcaption class="nx ny gj gh gi nz oa bd b be z dk">Image Credit — radiostudio.io</figcaption></figure><p id="c91a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是首先，我们需要在我们的服务器上安装NGINX。我在这个例子中使用的是CentOS 8，但是对于任何基于Linux的操作系统来说，步骤都是相似的，只不过在依赖管理器中做了适当的修改。</p><pre class="nn no np nq gt ob nf oc od aw oe bi"><span id="ede5" class="lv lw iq nf b gy of og l oh oi">sudo yum install -y epel-release<br/>sudo yum install -y nginx</span></pre><p id="a221" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于Ubuntu:</p><pre class="nn no np nq gt ob nf oc od aw oe bi"><span id="686e" class="lv lw iq nf b gy of og l oh oi">sudo apt update<br/>sudo apt install nginx</span></pre><p id="e2b3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下一个合乎逻辑的步骤是注册NGINX以便在系统启动时加载，为此，我们将使用:</p><pre class="nn no np nq gt ob nf oc od aw oe bi"><span id="5b27" class="lv lw iq nf b gy of og l oh oi">sudo systemctl start nginx<br/>sudo systemctl enable nginx</span></pre><p id="7850" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以使用以下命令检查正在运行的NGINX服务的状态:</p><pre class="nn no np nq gt ob nf oc od aw oe bi"><span id="9f7f" class="lv lw iq nf b gy of og l oh oi">sudo systemctl status nginx</span></pre><p id="10cf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这样，NGINX就可以使用NGINX附带的默认配置在您的服务器上安装和运行了。你可以通过点击你的服务器的IP地址来验证这一点，你会看到默认的NGINX登陆页面。</p><p id="bd46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，是时候根据我们的需要配置NGINX了，但在此之前，我们需要知道配置文件存储在哪里。默认的NGINX配置位于<code class="fe nc nd ne nf b">/etc/nginx/nginx.conf</code>中，有一个通配符匹配的include脚本，其中包含了来自— <code class="fe nc nd ne nf b">/etc/nginx/conf.d/*.conf</code>的任何子配置</p><p id="a233" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们将在该目录下创建一个新文件— <code class="fe nc nd ne nf b">touch /etc/nginx/conf.d/nodejs.conf</code>,并将以下配置复制到这个新创建的文件中。</p><figure class="nn no np nq gt nr"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="8986" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好的，同样，我将详细介绍和解释许多配置。</p><p id="e9d5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lu">上游名称</em> </strong> —该块定义了我们想要代理的不同应用程序。在这种情况下，我们有两个应用程序正在运行，一个在端口5000上，另一个在端口5001上。</p><p id="c14c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lu">服务器</em> </strong> —该块定义了应用于我们代理的每个应用程序的设置。</p><ul class=""><li id="1482" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la ol mz na nb bi translated"><em class="lu">监听</em> —这定义了NGINX监听的端口。定义了IPv4和IPv6两种类型。因此有两个listen指令。</li><li id="27b3" class="mt mu iq kh b ki ng kl nh ko ni ks nj kw nk la ol mz na nb bi translated"><em class="lu">服务器名称</em> —这是您的服务器的域名/IP地址</li><li id="077e" class="mt mu iq kh b ki ng kl nh ko ni ks nj kw nk la ol mz na nb bi translated"><em class="lu"> root </em> —这是存储应用程序的根文件夹</li></ul><p id="d9ea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lu">接下来的三个指令是可选的，但是强烈推荐。因为NGINX在内部将请求路由到我们的Node.js应用程序，所以我们的Node.js应用程序看到所有来自</em> <code class="fe nc nd ne nf b"><em class="lu">localhost</em></code> <em class="lu">的请求。因此，为了传递关于请求资源的实际IP地址的信息，我们将</em><strong class="kh ir"><em class="lu">proxy _ headers</em></strong><em class="lu">添加到请求中。</em></p><ul class=""><li id="4b91" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la ol mz na nb bi translated"><em class="lu">位置路线</em> —定义了所有需要代理的路线。<code class="fe nc nd ne nf b">/</code>意味着所有的请求都将被代理。proxy_pass属性定义了被代理的请求应该去哪里，注意我们在这里使用了上游名称。通过这样做，NGINX会根据哪个上游服务器可用，自动为我们进行负载平衡。</li></ul><p id="c31c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们将首先检查我们的NGINX配置是否有任何错误，因为在生产部署中，该文件中的错误直接等于应用程序停机时间，也就是损失。所以我们使用—</p><pre class="nn no np nq gt ob nf oc od aw oe bi"><span id="f8a4" class="lv lw iq nf b gy of og l oh oi">sudo nginx -t</span></pre><p id="3155" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果一切正常，那么我们使用<em class="lu"> systemctl: </em>重启/重新加载NGINX来应用这些新的更改</p><pre class="nn no np nq gt ob nf oc od aw oe bi"><span id="3828" class="lv lw iq nf b gy of og l oh oi">sudo systemctl reload nginx</span></pre><p id="14de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就这样，你做到了！您的Node.js应用程序现在已经正确地实现了负载平衡，并通过反向代理提供服务。</p><p id="4c1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在一切都好了，一切都将正常工作，直到你遇到一个用例，其中你必须利用WebSockets，突然如果你使用这种配置，WebSockets似乎不工作。嗯，很奇怪，不是吗？好吧，让我们看看我们是否能找出为什么它不起作用—</p><p id="a2de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lu"> WebSockets依靠</em> <strong class="kh ir"> <em class="lu">逐跳HTTP头</em> </strong> <em class="lu">尤其是(</em> <strong class="kh ir"> <em class="lu">连接</em> </strong> <em class="lu">和</em> <strong class="kh ir"> <em class="lu">升级</em> </strong> <em class="lu">)，而这些头</em> <strong class="kh ir"> <em class="lu"> </em> </strong> <em class="lu">是无法通过代理转发的。它们依赖于握手机制，该机制必须与服务器实例保持一致。</em></p><p id="dcc4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">阅读这篇令人惊叹的文章，了解更深入的解释:</p><div class="lb lc gp gr ld le"><a href="https://blog.usejournal.com/how-to-proxy-websockets-with-nginx-e333a5f0c0bb" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">如何用Nginx代理web sockets？</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">必须配置的web套接字头是什么？</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">blog.usejournal.com</p></div></div><div class="ln l"><div class="om l lp lq lr ln ls lt le"/></div></div></a></div><p id="92f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，为了解决这个问题，我们必须稍微修改我们的NGINX配置，并引入一些额外的指令:</p><figure class="nn no np nq gt nr"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="7881" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好吧，让我们看看发生了什么变化:</p><ul class=""><li id="c171" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la ol mz na nb bi translated"><em class="lu"> ip_hash </em> —这确保了来自一个客户端的所有请求都根据客户端的ip地址发送到同一个服务器实例</li><li id="cc63" class="mt mu iq kh b ki ng kl nh ko ni ks nj kw nk la ol mz na nb bi translated"><em class="lu"> location /socket.io/ </em> —该块定义了WebSockets正常工作所需的额外头文件— <strong class="kh ir"> <em class="lu"> Connection </em> </strong>和<strong class="kh ir"> <em class="lu"> Upgrade </em> </strong>，并且还将HTTP版本设置为1.1，该版本通过HTTP支持WebSockets。</li></ul><p id="1691" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">太好了！所以现在让我们测试并重新加载NGINX和boom，一切正常！</p><p id="d6be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">恭喜你！这样，Node.js应用程序就实现了负载平衡，并通过NGINX反向代理提供服务，Web套接字得到正确处理。在下一篇文章中，我们将扩展这个NGINX配置，以包括HTTPS和gzip压缩。</p><p id="7b6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要找到这种状态下的代码，请导航到GitHub库的<code class="fe nc nd ne nf b">nginx-1</code>分支:</p><div class="lb lc gp gr ld le"><a href="https://github.com/RyanDsilva/nodejs-in-production" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">RyanDsilva/生产中节点</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">⚙️在⚙️生产环境中部署Node.js应用程序的分步指南在生产环境中使用Node.js(第一部分)</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">github.com</p></div></div><div class="ln l"><div class="on l lp lq lr ln ls lt le"/></div></div></a></div><p id="8e87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">非常感谢你能走到这一步，我希望这是有用的。请分享这一点，并感谢任何反馈。第3部分见。</p><div class="lb lc gp gr ld le"><a href="https://medium.com/javascript-in-plain-english/using-node-js-in-production-part-iii-5a7a3f2fe942" rel="noopener follow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">在生产中使用Node.js(第三部分)</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">如何将Node.js应用程序部署到生产环境中，并拥有一个从开发到应用的健壮管道…</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">medium.com</p></div></div><div class="ln l"><div class="oo l lp lq lr ln ls lt le"/></div></div></a></div></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><p id="e746" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[1]NGINX Glossary—<a class="ae nl" href="https://www.nginx.com/resources/glossary/reverse-proxy-server/" rel="noopener ugc nofollow" target="_blank">https://www . NGINX . com/resources/Glossary/reverse-Proxy-server/</a><br/>【2】负载平衡—维基百科—<a class="ae nl" href="https://en.wikipedia.org/wiki/Load_balancing_(computing)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Load _ Balancing _(计算)</a><br/>【3】代理Web Sockets with NGINX—<a class="ae nl" href="https://blog.usejournal.com/how-to-proxy-websockets-with-nginx-e333a5f0c0bb" rel="noopener ugc nofollow" target="_blank">https://blog . use journal . com/how-to-Proxy-Web Sockets-with-NGINX-e 333 a5 f 0 c 0 bb</a></p></div></div>    
</body>
</html>